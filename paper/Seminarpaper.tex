% !TeX spellcheck = en_US
% This is LLNCS.DOC the documentation file of
% the LaTeX2e class from Springer-Verlag
% for Lecture Notes in Computer Science, version 2.4
\documentclass{llncs}
\usepackage{llncsdoc}
\usepackage{graphicx} 
\usepackage{booktabs}
%
\begin{document}
\thispagestyle{empty}
\rule{\textwidth}{1pt}
\vspace{2pt}
\begin{flushright}
\Huge
\begin{tabular}{@{}l}
Barriers to the\\
implementation of\\
k-anonymity and\\
related microdata\\
anonymization techniques\\
in a realworld application\\[6pt]

\end{tabular}
\end{flushright}
\rule{\textwidth}{1pt}
\vfill
\title{Barriers to the implementation of k-anonymity and related microdata anonymization techniques in a realworld application}
\author{Andreas Wiegnand, 1878334\\
	Ludwig Schallner, 1850413}
\institute{}
\maketitle
%
%\tableofcontents
\newpage
\setcounter{page}{1}
\section{Introduction}
%
Nowadays data is a key factor in nearly every domain. It is comparable to the gold rush of the \ensuremath{19^{th}.} century \cite{datarevo}. Furthermore, storage space and network increasingly become affordable \cite{sweeney2002k}. 
This is leading to the situation that the created and stored data is often not only useful to the original data holder, but to other researchers. Also, some data is only useful if its get shared with other data and get together analyzed. But those data may contain some personal or sensitive information. Such that the data should only get releases if the privacy is protected \cite{li2006achieving}.\\
\begin{table}[]
	\centering
	\caption{Basic example}
	\label{intro_example}
	\begin{tabular}{@{}llll@{}}
		\toprule
		SSN         & Age & Postcode & Problem         \\ \midrule
		680-90-2665 & 25  & 4568     & procrastination \\
		008-07-4179 & 34  & 4567     & stress          \\
		391-05-7998 & 48  & 4569     & stomach cancer  \\
		078-36-3853 & 39  & 4568     & obesity         \\
		411-71-9290 & 42  & 4561     & stomach ulcers  \\
		527-59-1948 & 27  & 4568     & stress          \\ \bottomrule
	\end{tabular}
\end{table}

Data like table \ref{intro_example} have to get anonymized before release. A very common
technique archive that goal is the so-called k-anonymity. Which goal is to prevent
the possibility that information about the individual gets leaked. This paper is
showing the process of implementing k-anonymity into the real world. In Section
1 we will explain mandatory basic to understand k-anonymity and its purpose.
Which leads to Section 2 the theoretical and heuristically implementation of
k-anonymity. Section 3 will discuss the underlying barriers of k-anonymity.
In Section 4 we will explain to the reader multiple algorithms to implement
k-anonymity and its barriers. A summary of the whole paper will be in the last section
\newpage
\section{Basics}
\subsubsection{Microdata:}
First of all, it should be clear what microdata is, those data is containing records of information about individuals. The upside versus the more known summary or aggregate data is, that microdata is naturally flexible. Everyone who has this data can perform own statistics from that data \cite{microdataweb}.
\subsubsection{Identifier:}
Attributes which can identify the record owner explicitly without any other attribute, for example full name (name and surname), telephone number, social security number. nicht sicher ob noch mehr möglich is\cite{domingo2008critique}
\subsubsection{Quasi-identifier:}
Even though explicit identifier got removed from published data. Attributes which non-explicitly identify the record owner are left. But if they get combined with other non-explicit attributes or other tables, they can reidentify the record owner. In such a case those combination of attributes are called quasi-identifier. For example Gender, Age, Postcode, weight and height \cite{dalenius1986finding}. Such process is shown in figure \ref{quasiidentifier}.
\subsubsection{Sensitive data:}
Data which is useful for example researchers but are private and should be known publicly nor be accessible for outsiders \cite{ldiversity}
\subsubsection{Background-knowledge:}
Because its unknown what the attackers knows, we have to assume additionally to that he have access to table, the attackers knows that the table is generalized (to guarantee k-anonymity). Furthermore the attacks is aware of the domain of the attributes.\\
\textbf{Instance-level background knowledge}
The adversary knows that his target does know specific details about his target. For example Alice (the adversary) knows that Bob do not suffer from some disease, because he does not show the symptoms. In this case the adversary may can conclude what Bob is really suffers from.\\
\textbf{Demographic background knowledge}
Adversary knows for example more general fact for example P(t[condition] = cancer| t[Age] $\geq$ 40). The attacker may use it to interference about records \cite{ldiversity}

\subsubsection{K-Anonymity}
The goal of making a k-anonymized table, is to have at least (k-1) tuples of each identical tuple taking the corresponding quasi-identifiers into account \cite{sweeney2002k,li2006achieving}. For example the 2-anonyminized version of the table \ref{intro_example} of introduction section
\subsubsection{Equivalence class}
Is a set of all tuples with the identical quasi-identifiers of a table \cite{li2006achieving}.
\subsubsection{global recoding/domain generalisation}
This generalization technique is very common, if a attribute value get generalized then all occourences of that value gets replaced by the generalized one \cite{sweeney2002k,sweeney2002achieving,li2006achieving,incognito}. 
\subsubsection{local recoding}
This coding strategies works differently from the above described one. Local recording generalizes attribute values in cells. Because of that this strategies doenst over generalize the table and the data distortion is significantly lower \cite{li2006achieving}. 

\section{Theoretical and heuristically implantation of K-Anonymity}
Another problem we will introduce is, that the producing of k-anonymity of a computational view is an NP-hard problem, like Meyersond and Williams shown.
 
\section{Underlying Barriers}

In the following section, we will show the basic and most challenging barriers to the implementation of k-Anonymity. First, we will show the barrier which appears if you k-anonymize the data, the so-called \textbf{distortion} of data, in some papers it also mentioned as data loss. 
%checked
\subsection{Distortion} 
A basic underlying barrier of k-anonymity is, how to measure if a implantation has been successful or leads to a satisfying result. This can be measured by a simple calculation. The \textbf{modification rate} is representing the fraction of cells which got modified within the attribute set of the quasi-identifier. The example of table 2 will be following through the whole section, to guarantee an easy understanding the different approaches. \\
% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
\begin{table}[]
	\centering
	\label{table2}
	\begin{tabular}{lllllllllll}
		\cline{1-3} \cline{5-7} \cline{9-11}
		Gender & Birthday   & Problem &  & Gender & Birthday   & Problem &  & Gender & Birthday & Problem \\ \cline{1-3} \cline{5-7} \cline{9-11} 
		male   & 13.08.1962 & stress  &  & male   & 13.08.1962 & stress  &  & *      & 196*     & stress  \\
		male   & 28.10.1967 & obesity &  & male   & 28.10.1967 & obesity &  & *      & 196*     & obesity \\
		male   & 20.01.1977 & stress  &  & *      & 197*       & stress  &  & *      & 197*     & stress  \\
		female & 15.09.1973 & obesity &  & *      & 197*       & obesity &  & *      & 197*     & obesity \\
		female & 15.03.1985 & stress  &  & female & 15.03.1985 & stress  &  & *      & 198*     & stress  \\
		female & 28.05.1986 & obesity &  & female & 28.05.1986 & obesity &  & *      & 198*     & obesity \\ \cline{1-3} \cline{5-7} \cline{9-11}
		
	\end{tabular}
	\caption{Left original table, middle: example for local recording, right: example for domain generalization }
\end{table}
and to understand would be the calculation of distortion by Li, Wong, Fu, and Pei \cite{li2006achieving}. 
For calculating the weighted hierarchical distance of a cell which got generalized from level p to level q following formula is resulting to the solution.\\
$ WHD (p, q) = \frac{\sum_{j=q+1}^{p} \omega_{j,j-1}}{\sum_{j=2}^{h} \omega_{j,j-1}} $

\subsubsection{Distortions of generalization of tuples}
\subsubsection{Distortions of generalization of tables}
\subsubsection{Conclusion}

\subsection{NP Hard}

\subsection{Attacks}

Like Dalenius already mentioned it is absolutely necessary that an attacker, under no circumstances, can learn about whatsoever target if he is studying the published database. Not even if the attacker has background knowledge from any other sources  \cite{Dalenius1977}. Unfortunately like Dwork showed 2006 that such safety is impossible because of background knowledge. For example, if the attacker knows that Bob get paid twice as the average German man and the attacker got access to a database which publishes the average income by German men. The anonymity of Bob is compromised even if Bob's data is not in the database \cite{dwork2011differential}.  
Ab hier noch mal komplett die Attacken überarbeiten, da noch im orginal ursprung!
\subsubsection{Linking data}
A barrier to do the implementation of k-anonymity, the attacker can take another dataset and link both together to get rid off the k-anonymity and infer the real individual. This process is called linking data and was first described by Sweeney\cite{sweeney2002k}. She showed that with a example of health care data from 37 states in the USA. The institute from which she bought the data, insures the anonymity of the individuals. Sweeney purchased the voter registration list for Cambridge Massachusettts and received information of the voters including ZIP code, birth date and gender (non explicit identifier) of each voter. She linked that information with the medical data. It was possible to deanonymize the data  and get ethnicity, visit date, diagnosis, procedure, medication and total charge of some patients \cite{sweeney2002k}. 

\begin{figure}[]
	\centering
	\includegraphics[width=0.7\textwidth]{linkingdata.png}
	\caption{linking data}%
	\label{quasiidentifier}
\end{figure}
You got two datasets A and B. Each dataset got \ensuremath{\langle f_1, ... ,f_n \rangle} features and \ensuremath{\langle r_1, ... ,r_n \rangle} rows.
Each row is then a tuple \ensuremath{r_i} with n features \ensuremath{\langle f_1, ... ,f_n \rangle} describing the individual.
Even tho the data is k-anonimized you can get rid oft he anonymity of the individual by linking the A to B. So if \ensuremath{A \cap B \not \neq \emptyset} it is possible to infer the anonymized individual \cite{sweeney2002k}.
As a result any attacker who know such data (ZIP Code, Birth date and sex) could easily identify with such an attack his victim. For example Peter see his ex-wife at the doctor, most likely he knows her ZIP-Code, Birth date and sex. Therefore he finds out what she is suffer from. 
\subsubsection{Unsorted matching attack against k-anonymity}
There is a possibility of a leak of information, if the release k-anonymity data is in some kind of a sort release. This mean the numerical attributes are descending or ascending sorted and attributes, which be of characters are alphabetical ordered, can give the attacker Information about the sensitive data. To prevent this attack, just get the data into a random order with a pseudo randomized sorting algorithm \cite{sweeney2002k}. As an example take a look at the table 3: matching attack  will give an example on that. If you compare the different release generalized tables you can figure out all quasi identifier of those \cite{sweeney2002k}.
\\...
\begin{table}	
	\caption{matching attack}
	\centering
	\begin{tabular}[t]{|l|l|}		
	\hline
	Age & ZIP   \\ \hline
	2   & 91058 \\ 
	4   & 91058 \\ 
	50  & 27785 \\ 
	52  & 27785 \\ 
	20  & 32105 \\ 
	21  & 32105 \\ 
	31  & 67676 \\ 
	32  & 67676 \\ \hline
		\end{tabular}
	\hfill
	\begin{tabular}[t]{|l|l|}
	\hline
	Age & ZIP   \\ \hline
	*   & 91058 \\
	**   & 91058 \\
	5*  & 27785 \\
	5*  & 27785 \\
	2*  & 32105 \\
	2*  & 32105 \\
	3*  & 67676 \\
	3*  & 67676 \\ \hline  
	\end{tabular}
	\hfill
	\begin{tabular}[t]{|l|l|}
	\hline
	Age & ZIP   \\	\hline
	2   & 91*   \\
	4   & 91*   \\
	50  & 27*   \\
	52  & 27*   \\
	20  & 32*   \\
	21  & 32*   \\
	31  & 67*   \\
	32  & 67*   \\ \hline  
	\end{tabular}
\end{table}
\subsubsection{Complexity of producing k-anonymity}
BRauchen wir das????
Till now we only looked at problems of information leaking and privacy problems for individuals. Data is personal-specific information which is structured as a table in rows and columns. Rows a tuple. The columns are attributes with are a set of values which describe the certain attribute. A tuple specify a person. K-anonymity is about protecting the identity of a person not relationships of companies or governments. So the goal of k-anonymity is, not getting more information by linking the data to external data. The bridge between the data and external data is called "quasi-identifier". Examples for that would be ZIP, gender, birth date etc.. \\
\\
Generalization mean, replacing a value with a less specific but semantic identical value. For example we got a list of forenames of buys, (Achmed, Achilles, Achim). To generalize this names you can just (Ach*,Ach*, Ach*) delete the last chars of the name. So there is a less specific domain and now more generalize through this mapping. Suppression on the other hand means not releasing the value at all.
\section{Algorithm}
\subsection{Clustering}
Needed because data contains categorical values, the methods are not quite effective.
\cite{li2006achieving}
\subsection{Datafly}
\subsection{Argus}
\section{Releated techniques}
\section{Summary}

\newpage
\bibliography{literature}
\bibliographystyle{splncs03}

\end{document}


